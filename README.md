# Hand Gesture-to-Voice-
# Gesture-Based Speech Application

This project implements a gesture-based speech application using computer vision and machine learning techniques. It recognizes six distinct hand gestures and speaks the corresponding words aloud.

## Features

* **Gesture Recognition:** Detects six different hand gestures.
* **Speech Output:** Speaks the corresponding word for each detected gesture.
* **Custom Dataset:**  Trained on a custom dataset of six words: I, you, ok, Good Job, am, are.
* **Real-time Detection:**  Processes video input in real-time.

## Technologies Used

* **Frontend:** HTML, JavaScript,CSS
* **Backend:** Python
* **Machine Learning:** OpenCV, MobileNet architecture, Model training with .h5 extension
* **Dataset:** Custom dataset (6 words)
